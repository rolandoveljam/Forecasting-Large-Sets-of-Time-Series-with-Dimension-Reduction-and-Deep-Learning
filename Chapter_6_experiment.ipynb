{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77ed4cc",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3222ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import keras_tuner as kt\n",
    "from keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff9f0d",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Rolando/Desktop/FREDMDApril19.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a78be",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8780750",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "train=df.iloc[:int(0.7*(n-5)),]\n",
    "val=df.iloc[int(0.7*(n-5)):(n-5),]\n",
    "test=df.iloc[(n-5):n,]\n",
    "Varnames=df.columns\n",
    "Housing=['HOUST','HOUSTNE','HOUSTMW','HOUSTS','HOUSTW','PERMIT','PERMITNE','PERMITMW','PERMITS','PERMITW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604fa288",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4953ed84",
   "metadata": {},
   "source": [
    "# Evolution of Housing features over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400dc781",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df[Housing],label=Housing)\n",
    "plt.xticks(ticks=[118+120*i for i in range(5)], labels=[1970+10*i for i in range(5)])\n",
    "plt.axvline(x=len(train), color='black',linestyle='dashed', alpha=0.7)\n",
    "plt.axvline(x=n-5, color='black',linestyle='dashed', alpha=0.7)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49abf1",
   "metadata": {},
   "source": [
    "# ACFs and PACFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 4, figsize=(15, 20))\n",
    "for i in range(10):\n",
    "    plot_acf(train[Housing].iloc[:,i], ax=axes[i%5,0+2*(i%2)])\n",
    "    axes[i%5,0+2*(i%2)].set_title(f'ACF for {Housing[i]}')\n",
    "    plot_pacf(train[Housing].iloc[:,i], ax=axes[i%5,1+2*(i%2)])\n",
    "    axes[i%5,1+2*(i%2)].set_title(f'PACF for {Housing[i]}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a4a21",
   "metadata": {},
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ef16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train.mean()\n",
    "train_std = train.std() \n",
    "\n",
    "train_df = (train - train_mean) / train_std\n",
    "val_df = (val - train_mean) / train_std\n",
    "test_df = (test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef2461",
   "metadata": {},
   "source": [
    "# Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WindowData(lag, train_df=train_df,val_df=val_df,test_df=test_df,val=True):\n",
    "    time_steps_lag=lag\n",
    "    time_steps_h=5\n",
    "\n",
    "    # Reshape train\n",
    "\n",
    "    n_samples = train_df.shape[0] - time_steps_lag - time_steps_h + 1\n",
    "    n_features = train_df.shape[1]\n",
    "    n_features_y = 10\n",
    "\n",
    "    X = np.zeros((n_samples, time_steps_lag, n_features))\n",
    "    y = np.zeros((n_samples, time_steps_h, n_features_y))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        X[i] = train_df[i:i+time_steps_lag]\n",
    "        y[i] = train_df[Housing][i+time_steps_lag:i+time_steps_lag+time_steps_h]\n",
    "\n",
    "    train_X = X\n",
    "    train_Y = y\n",
    "\n",
    "    if val:\n",
    "        # Reshape val\n",
    "\n",
    "        n_samples = val_df.shape[0] - time_steps_h + 1\n",
    "        n_features = val_df.shape[1]\n",
    "        n_features_y = 10\n",
    "\n",
    "        X = np.zeros((n_samples, time_steps_lag, n_features))\n",
    "        y = np.zeros((n_samples, time_steps_h, n_features_y))\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            if (i==0):\n",
    "                X[i]=train_df[train_df.shape[0]-time_steps_lag:train_df.shape[0]]\n",
    "            elif (i<time_steps_lag):\n",
    "                X[i,0:time_steps_lag-i] = train_df[train_df.shape[0]-time_steps_lag+i:train_df.shape[0]]\n",
    "                X[i,time_steps_lag-i:time_steps_lag] = val_df[time_steps_lag-i:time_steps_lag]\n",
    "            else:\n",
    "                X[i] = val_df[i-time_steps_lag:i]\n",
    "            y[i] = val_df[Housing][i:i+time_steps_h]\n",
    "\n",
    "        val_X = X\n",
    "        val_Y = y\n",
    "\n",
    "        # Reshape test\n",
    "\n",
    "        n_samples = test.shape[0] - time_steps_h + 1\n",
    "        n_features = test.shape[1]\n",
    "        n_features_y = 10\n",
    "\n",
    "        X = np.zeros((n_samples, time_steps_lag, n_features))\n",
    "        y = np.zeros((n_samples, time_steps_h, n_features_y))\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            if (i==0):\n",
    "                X[i]=val_df[val_df.shape[0]-time_steps_lag:val_df.shape[0]]\n",
    "            elif (i<time_steps_lag):\n",
    "                X[i,0:time_steps_lag-i] = val_df[val_df.shape[0]-time_steps_lag+i:val_df.shape[0]]\n",
    "                X[i,time_steps_lag-i:time_steps_lag] = test_df[time_steps_lag-i:time_steps_lag]\n",
    "            else:\n",
    "                X[i] = test_df[i-time_steps_lag:i]\n",
    "            y[i] = test_df[Housing][i:i+time_steps_h]\n",
    "\n",
    "        test_X = X\n",
    "        test_Y = y\n",
    "        return train_X, train_Y, val_X, val_Y, test_X, test_Y\n",
    "    else :\n",
    "                # Reshape test\n",
    "\n",
    "        n_samples = test.shape[0] - time_steps_h + 1\n",
    "        n_features = test.shape[1]\n",
    "        n_features_y = 10\n",
    "\n",
    "        X = np.zeros((n_samples, time_steps_lag, n_features))\n",
    "        y = np.zeros((n_samples, time_steps_h, n_features_y))\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            if (i==0):\n",
    "                X[i]=train_df[train_df.shape[0]-time_steps_lag:train_df.shape[0]]\n",
    "            elif (i<time_steps_lag):\n",
    "                X[i,0:time_steps_lag-i] = train_df[train_df.shape[0]-time_steps_lag+i:train_df.shape[0]]\n",
    "                X[i,time_steps_lag-i:time_steps_lag] = test_df[time_steps_lag-i:time_steps_lag]\n",
    "            else:\n",
    "                X[i] = test_df[i-time_steps_lag:i]\n",
    "            y[i] = test_df[Housing][i:i+time_steps_h]\n",
    "\n",
    "        test_X = X\n",
    "        test_Y = y\n",
    "        return train_X, train_Y, test_X, test_Y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8d3f1",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3df6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp,seedp=0):\n",
    "    # Clear session\n",
    "    K.clear_session()\n",
    "    # Seeds\n",
    "    keras.utils.set_random_seed(100510766+seedp)\n",
    "    # Model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Hyperparameters\n",
    "    hp_units = hp.Choice('units', values=[32,64,128,256,512,1024])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) \n",
    "    hp_activation = hp.Choice('activation', values=['relu','tanh']) \n",
    "    hp_dropout=hp.Choice('dropout',values=[float(0), 0.1, 0.2, 0.3]) \n",
    "    hp_kernel_reg = hp.Choice('kernel_regularizer', values=[float(0), 1e-3, 1e-2, 1e-1])\n",
    "    # Layers\n",
    "    model.add(tf.keras.layers.LSTM(units=hp_units, return_sequences=False, dropout=hp_dropout))\n",
    "    # Output\n",
    "    model.add(tf.keras.layers.Dense(50, activation=hp_activation, kernel_regularizer=regularizers.L2(hp_kernel_reg)))  \n",
    "    model.add(tf.keras.layers.Reshape((5, 10))) \n",
    "    model.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                    optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), \n",
    "                    metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "train_X_list=[]\n",
    "train_Y_list=[]\n",
    "val_X_list=[]\n",
    "val_Y_list=[]\n",
    "test_X_list=[]\n",
    "test_Y_list=[] \n",
    "hp_lags=[1,3,6,12,18,24] \n",
    "for lag in hp_lags:\n",
    "    train_X, train_Y, val_X, val_Y, test_X, test_Y = WindowData(lag)\n",
    "    train_X_list.append(train_X)\n",
    "    train_Y_list.append(train_Y)\n",
    "    val_X_list.append(val_X)\n",
    "    val_Y_list.append(val_Y)\n",
    "    test_X_list.append(test_X)\n",
    "    test_Y_list.append(test_Y)\n",
    "    \n",
    "    \n",
    "best_hps_per_window = []\n",
    "best_metrics_per_window = []\n",
    "best_tuner_per_window = []\n",
    "best_model_per_window = []\n",
    "\n",
    "start_time = time.time()    \n",
    "for i in range(len(hp_lags)):\n",
    "    nombre_archivo = 'numero.csv'\n",
    "    # csv stating which lag is currently working on\n",
    "    with open(nombre_archivo, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Lag'])  \n",
    "        writer.writerow([hp_lags[i]])    \n",
    "\n",
    "    tuner = kt.GridSearch(model_builder,\n",
    "                    objective='val_loss',\n",
    "                   project_name=f'Search_{hp_lags[i]}_lags')\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "    \n",
    "    tuner.search(train_X_list[i], train_Y_list[i], epochs=200, validation_data=(val_X_list[i], val_Y_list[i]), callbacks=[stop_early])\n",
    "    \n",
    "    best_model=tuner.get_best_models(num_models=1)[0]\n",
    "    best_model_per_window.append(best_model)\n",
    "    \n",
    "    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_hps_per_window.append(best_hps)\n",
    "    \n",
    "    train_loss, train_mse = best_model.evaluate(train_X_list[i], train_Y_list[i])\n",
    "    val_loss, val_mse = best_model.evaluate(val_X_list[i], val_Y_list[i])\n",
    "\n",
    "    best_metrics_per_window.append({\n",
    "        'train_loss': train_loss,\n",
    "        'train_mse': train_mse,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mse': val_mse\n",
    "    })\n",
    "    best_tuner_per_window.append(tuner)\n",
    "\n",
    "best_window_index = min(range(len(best_metrics_per_window)), key=lambda i: best_metrics_per_window[i]['val_loss'])\n",
    "best_hps = best_hps_per_window[best_window_index]\n",
    "best_metrics = best_metrics_per_window[best_window_index]\n",
    "best_model = best_model_per_window[best_window_index]\n",
    "best_tuner = best_tuner_per_window[best_window_index]\n",
    "\n",
    "print(f\"Best window lag: {hp_lags[best_window_index]}\")\n",
    "print(f\"Best hyperparameters: {best_hps.get('units')} units, {best_hps.get('activation')} activation, {best_hps.get('learning_rate')} learning rate, {best_hps.get('dropout')} dropout, {best_hps.get('kernel_regularizer')} regularizer.\")\n",
    "print(f\"Best metrics: {best_metrics}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time elapsed: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58b56b",
   "metadata": {},
   "source": [
    "## Check history for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f97cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seed is established so same results as best_model in tuning\n",
    "train_X, train_Y, val_X, val_Y, test_X, test_Y = WindowData(hp_lags[best_window_index])\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "model = model_builder(best_hps)\n",
    "history = model.fit(train_X, train_Y, epochs=200, validation_data=(val_X, val_Y), callbacks=[stop_early])\n",
    "\n",
    "val_mae_per_epoch = history.history['val_loss']\n",
    "best_epoch = val_mae_per_epoch.index(min(val_mae_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc320278",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'], label=\"Validation\")\n",
    "plt.plot(history.history['loss'],label=\"Train\")\n",
    "plt.legend()\n",
    "plt.axvline(best_epoch-1, ls=\"--\",color=\"green\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b56a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = best_model.evaluate(test_X, test_Y)\n",
    "print(\"[test loss, test MSE]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f70e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=best_model.predict(test_X)[0,:,:]\n",
    "for i in range(preds.shape[1]):\n",
    "    preds[:,i]=preds[:,i]*train_std[Housing][i]+train_mean[Housing][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bde26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(preds,np.array(test[Housing]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b93811",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(preds,np.array(test[Housing]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df1d7b",
   "metadata": {},
   "source": [
    "# Model trained with train + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df.iloc[:(n-5),]\n",
    "train_mean = train.mean(); \n",
    "train_std = train.std();\n",
    "\n",
    "train_df = (train - train_mean) / train_std\n",
    "test_df = (test - train_mean) / train_std\n",
    "\n",
    "train_X, train_Y, test_X, test_Y = WindowData(hp_lags[best_window_index],train_df=train_df,test_df=test_df,val=False)\n",
    "model = model_builder(best_hps)\n",
    "model.fit(x=train_X, y=train_Y, epochs=best_epoch)\n",
    "\n",
    "preds_LSTM_1=model.predict(test_X)[0,:,:]\n",
    "for i in range(preds_LSTM_1.shape[1]):\n",
    "    preds_LSTM_1[:,i]=preds_LSTM_1[:,i]*train_std[Housing][i]+train_mean[Housing][i]\n",
    "\n",
    "# Different initializations\n",
    "\n",
    "MAE_test_1 = []\n",
    "MSE_test_1 = []\n",
    "for j in range(10):\n",
    "    model = model_builder(best_hps, seedp=j)\n",
    "    model.fit(x=train_X, y=train_Y, epochs=best_epoch)\n",
    "    preds=model.predict(test_X)[0,:,:]\n",
    "    for i in range(preds.shape[1]):\n",
    "        preds[:,i]=preds[:,i]*train_std[Housing][i]+train_mean[Housing][i]\n",
    "    MAE_test_1.append(mean_absolute_error(preds,np.array(test[Housing])))\n",
    "    MSE_test_1.append(mean_squared_error(preds,np.array(test[Housing])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a4690",
   "metadata": {},
   "source": [
    "# LSTM with 2 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0afcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder2(hp,seedp=0):\n",
    "    # Seeds\n",
    "    keras.utils.set_random_seed(100510766+seedp)\n",
    "    # Model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Hyperparameters\n",
    "    units_choices = ['64_32','128_64','256_128','512_256','1024_512','1024_1024','2048_1024']\n",
    "    selected_units = hp.Choice('units', units_choices)\n",
    "    units = list(map(int, selected_units.split('_')))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) \n",
    "    hp_activation = hp.Choice('activation', values=['relu','tanh']) \n",
    "    hp_dropout=hp.Choice('dropout',values=[float(0), 0.1, 0.2, 0.3]) \n",
    "    hp_kernel_reg = hp.Choice('kernel_regularizer', values=[float(0), 1e-3, 1e-2, 1e-1])\n",
    "    # Layers\n",
    "    model.add(tf.keras.layers.LSTM(units=units[0], return_sequences=True, dropout=hp_dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units=units[1], return_sequences=False, dropout=hp_dropout))\n",
    "    # Output\n",
    "    model.add(tf.keras.layers.Dense(50, activation=hp_activation, kernel_regularizer=regularizers.L2(hp_kernel_reg)))   \n",
    "    model.add(tf.keras.layers.Reshape((5, 10))) \n",
    "    model.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                    optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), \n",
    "                    metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "train_X_list=[]\n",
    "train_Y_list=[]\n",
    "val_X_list=[]\n",
    "val_Y_list=[]\n",
    "test_X_list=[]\n",
    "test_Y_list=[] \n",
    "hp_lags=[1,3,6,12,18,24]\n",
    "for lag in hp_lags:\n",
    "    train_X, train_Y, val_X, val_Y, test_X, test_Y = WindowData(lag)\n",
    "    train_X_list.append(train_X)\n",
    "    train_Y_list.append(train_Y)\n",
    "    val_X_list.append(val_X)\n",
    "    val_Y_list.append(val_Y)\n",
    "    test_X_list.append(test_X)\n",
    "    test_Y_list.append(test_Y)\n",
    "    \n",
    "    \n",
    "best_hps_per_window = []\n",
    "best_metrics_per_window = []\n",
    "best_tuner_per_window = []\n",
    "best_model_per_window = []\n",
    "\n",
    "start_time = time.time()    \n",
    "for i in range(len(hp_lags)):\n",
    "    nombre_archivo = 'numero.csv'\n",
    "    # csv stating which lag is currently working on\n",
    "    with open(nombre_archivo, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Lag'])  \n",
    "        writer.writerow([hp_lags[i]])   \n",
    "\n",
    "    tuner = kt.GridSearch(model_builder2,\n",
    "                    objective='val_loss',\n",
    "                   project_name=f'Search2_{hp_lags[i]}_lags')\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "    \n",
    "    tuner.search(train_X_list[i], train_Y_list[i], epochs=200, validation_data=(val_X_list[i], val_Y_list[i]), callbacks=[stop_early])\n",
    "    \n",
    "    best_model=tuner.get_best_models(num_models=1)[0]\n",
    "    best_model_per_window.append(best_model)\n",
    "    \n",
    "    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_hps_per_window.append(best_hps)\n",
    "    \n",
    "    train_loss, train_mse = best_model.evaluate(train_X_list[i], train_Y_list[i])\n",
    "    val_loss, val_mse = best_model.evaluate(val_X_list[i], val_Y_list[i])\n",
    "\n",
    "    best_metrics_per_window.append({\n",
    "        'train_loss': train_loss,\n",
    "        'train_mse': train_mse,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mse': val_mse\n",
    "    })\n",
    "    best_tuner_per_window.append(tuner)\n",
    "\n",
    "best_window_index = min(range(len(best_metrics_per_window)), key=lambda i: best_metrics_per_window[i]['val_loss'])\n",
    "best_hps = best_hps_per_window[best_window_index]\n",
    "best_metrics = best_metrics_per_window[best_window_index]\n",
    "best_model = best_model_per_window[best_window_index]\n",
    "best_tuner = best_tuner_per_window[best_window_index]\n",
    "\n",
    "print(f\"Best window lag: {hp_lags[best_window_index]}\")\n",
    "print(f\"Best hyperparameters: {best_hps.get('units')} units, {best_hps.get('activation')} activation, {best_hps.get('learning_rate')} learning rate, {best_hps.get('dropout')} dropout, {best_hps.get('kernel_regularizer')} regularizer.\")\n",
    "print(f\"Best metrics: {best_metrics}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time elapsed: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6dcea",
   "metadata": {},
   "source": [
    "## Check history for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abccb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed is established so same results as best_model in tuning\n",
    "train_X, train_Y, val_X, val_Y, test_X, test_Y = WindowData(hp_lags[best_window_index])\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "model = model_builder2(best_hps)\n",
    "history = model.fit(train_X, train_Y, epochs=200, validation_data=(val_X, val_Y), callbacks=[stop_early])\n",
    "\n",
    "val_mae_per_epoch = history.history['val_loss']\n",
    "best_epoch = val_mae_per_epoch.index(min(val_mae_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'], label=\"Validation\")\n",
    "plt.plot(history.history['loss'],label=\"Train\")\n",
    "plt.legend()\n",
    "plt.axvline(best_epoch-1, ls=\"--\",color=\"green\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc45d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = best_model.evaluate(test_X, test_Y)\n",
    "print(\"[test loss, test MSE]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40090844",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_LSTM_2=best_model.predict(test_X)[0,:,:]\n",
    "for i in range(preds_LSTM_2.shape[1]):\n",
    "    preds_LSTM_2[:,i]=preds_LSTM_2[:,i]*train_std[Housing][i]+train_mean[Housing][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(preds_LSTM_2,np.array(test[Housing]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(preds_LSTM_2,np.array(test[Housing]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3ca9f",
   "metadata": {},
   "source": [
    "# Model trained with train + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df.iloc[:(n-5),]\n",
    "train_mean = train.mean(); \n",
    "train_std = train.std();\n",
    "\n",
    "train_df = (train - train_mean) / train_std\n",
    "test_df = (test - train_mean) / train_std\n",
    "\n",
    "train_X, train_Y, test_X, test_Y = WindowData(hp_lags[best_window_index],train_df=train_df,test_df=test_df,val=False)\n",
    "model = model_builder2(best_hps)\n",
    "model.fit(x=train_X, y=train_Y, epochs=best_epoch)\n",
    "\n",
    "preds_LSTM_1=model.predict(test_X)[0,:,:]\n",
    "for i in range(preds_LSTM_1.shape[1]):\n",
    "    preds_LSTM_1[:,i]=preds_LSTM_1[:,i]*train_std[Housing][i]+train_mean[Housing][i]\n",
    "\n",
    "# Different initializations\n",
    "\n",
    "MAE_test_2 = []\n",
    "MSE_test_2 = []\n",
    "for j in range(10):\n",
    "    model = model_builder2(best_hps, seedp=j)\n",
    "    model.fit(x=train_X, y=train_Y, epochs=best_epoch)\n",
    "    preds=model.predict(test_X)[0,:,:]\n",
    "    for i in range(preds.shape[1]):\n",
    "        preds[:,i]=preds[:,i]*train_std[Housing][i]+train_mean[Housing][i]\n",
    "    MAE_test_2.append(mean_absolute_error(preds,np.array(test[Housing])))\n",
    "    MSE_test_2.append(mean_squared_error(preds,np.array(test[Housing])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e438e",
   "metadata": {},
   "source": [
    "# Plotting all predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aca45a",
   "metadata": {},
   "source": [
    "## Loading csv's with other models predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_baseline=pd.DataFrame([df[Housing][700:705].mean()]*5)\n",
    "preds_DFM_forecast= pd.read_csv('C:/Users/Rolando/Desktop/y_DFM.csv')\n",
    "preds_DFMN_SLBDD= pd.read_csv('C:/Users/Rolando/Desktop/y_DFMN.csv')\n",
    "preds_GDFM= pd.read_csv('C:/Users/Rolando/Desktop/y_GDFM_factor.csv')\n",
    "preds_GDFM_forecast= pd.read_csv('C:/Users/Rolando/Desktop/y_GDFM.csv')\n",
    "preds_GDFM_SLBDD= pd.read_csv('C:/Users/Rolando/Desktop/y_GDFMN.csv')\n",
    "preds_LSTM_1=pd.DataFrame(preds_LSTM_1)\n",
    "preds_LSTM_2=pd.DataFrame(preds_LSTM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c043fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(MAE_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac34c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(MAE_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c178996",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 2, figsize=(15, 25))\n",
    "for i in range(10):\n",
    "    axes[i%5, int(i>4)].plot(preds_baseline.iloc[:,i], color=\"deeppink\")\n",
    "    axes[i%5, int(i>4)].plot(preds_DFM_forecast.iloc[:,i], color=\"orange\")\n",
    "    axes[i%5, int(i>4)].plot(preds_DFMN_SLBDD.iloc[:,i], color=\"sienna\")\n",
    "    axes[i%5, int(i>4)].plot(preds_GDFM.iloc[:,i], color=\"yellow\")\n",
    "    axes[i%5, int(i>4)].plot(preds_GDFM_SLBDD.iloc[:,i], color=\"purple\")\n",
    "    axes[i%5, int(i>4)].plot(preds_GDFM_forecast.iloc[:,i], color=\"lime\")\n",
    "    axes[i%5, int(i>4)].plot(preds_LSTM_1.iloc[:,i], color=\"red\")\n",
    "    axes[i%5, int(i>4)].plot(preds_LSTM_2.iloc[:,i], color=\"cyan\")\n",
    "    axes[i%5, int(i>4)].plot(np.array(test[Housing].iloc[:,i]), color=\"blue\")\n",
    "    axes[i%5, int(i>4)].set_title(f'{Housing[i]}')\n",
    "fig.subplots_adjust(wspace=0.2)\n",
    "axes.flatten()[-1].legend([\"Baseline\", \"DFM_forecast\", \"DFM_SLBDD\", \"GDFM\", \"GDFM_forecast\", \n",
    "                           \"GDFM_SLBDD\", \"LSTM_1\", \"LSTM_2\", \"True value\"], loc='upper left', bbox_to_anchor=(-1.3, -0.2), shadow=True, ncol=9)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
